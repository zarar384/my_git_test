1) Monolith плохо масштабируется по командам и по скорости изменений.
Microservices увеличивают гибкость, но сильно усложняют наблюдаемость.

Связь microservices ↔ CI/CD ↔ Observability(diagnosis)
Monolith ≈ Waterfall: Долгий цикл: requirements => design => code => test => deploy
Microservices ≈ CI/CD: Короткий цикл: plan => code => build => test => deploy => measure => repeat
CI/CD без observability - опасно.
Чем чаще деплой - тем больше нужен мониторинг и трассировка.

Почему Observability ОБЯЗАТЕЛЬНА в microservices? В microservices нельзя понять, что происходит, без observability.

Вывод: Observability is essential for microservices because failures are inevitable, deployments are frequent, and system behavior cannot be understood without metrics, logs, and traces.
или же: The more microservices you have, the more observability you need.

Вопросы:
1. Почему microservices требуют observability? много сервисов; сложные зависимости; distributed failures; невозможно дебажить без метрик, логов и трейсов.
2. Почему CI/CD увеличивает требования к мониторингу? частые деплои; каждый деплой несёт риск; нужно быстро обнаруживать деградации и откатываться.
3. Почему monolith проще мониторить? один процесс; одна база; один лог; один entry point.
4. Что происходит без observability? blind deployments; долгое MTTR; сложно найти root cause; нестабильная система.

2) Monitoring - это: регулярный сбор и визуализация runtime-данных системы, чтобы отслеживать её здоровье.
!regularly!

Три ГЛАВНЫХ вопроса мониторинга:
* Is the service ON? Обычно проверяется через: health checks; ping / HTTP HEAD / GET.
* Is the service FUNCTIONING as expected? thresholds или же 'Если ошибок < 5 в минуту => считаем нормой'.
* Is the service PERFORMING well?  'HTTP response time ≤ 20 ms => OK'

Три ГЛАВНЫХ вопроса по аналогии с машиной:
* ON => двигатель крутится (RPM > 0)
* FUNCTIONING => машина едет
* PERFORMANCE => нет warning lights, нормальные показатели

Telemetry data - это данные, которые мы собираем для мониторинга: метрики; логи; события; трейсы.
!Telemetry data показывает ГДЕ проблема, но не всегда ПОЧЕМУ!

Monitoring ≠ Debugging
Monitoring(detection): указывает на аномалию; показывает симптомы.
Debugging: ищет root cause; требует логов и трейсов.

Без мониторинга microservices превращаются в black box.

DevOps метрики:
* MTD - Mean Time to Detection: Среднее время от начала инцидента до его обнаружения.
показывает: качество мониторинга; качество алертов.
* MTR / MTTR - Mean Time to Resolve: Среднее время от обнаружения проблемы до её полного устранения.
Что показывает: качество observability; качество процессов; зрелость команды.

Вопросы:
1. Какие вопросы должен отвечать мониторинг? Is the service up? Is it working correctly? Is it performing well?
2. В чём разница между monitoring и observability? Monitoring tells you that something is wrong, observability helps you understand why.
3. Что такое telemetry data? Runtime data (metrics, logs, traces) used to monitor system health and behavior.
4. Что такое MTD и MTTR? MTD => time to detect a problem; MTTR => time to fix it.

3) Какие ключевые метрики собираются для Monitoring? Собирать нужно не 'всё подряд', а только meaningful metrics.
Система обычно состоит из 3 слоёв:
* UI layer (Web / Mobile)
* Service layer (microservices)
* Infrastructure layer (CPU, memory, disk, network)
Под каждый слой - свои метрики.

* RED Method (Service + частично UI) - Request-driven metrics, где RED = Rate, Errors, Duration - cамый популярный метод для microservices.
RED method focuses on how a service behaves from the user’s perspective.
R - Rate (Throughput): Requests per second; Traffic volume. - 2M requests/sec
E - Errors: HTTP 5xx; business errors; fatal exceptions. - Смотрим error rate, а не просто количество.
D - Duration (Latency): Response time; P95 / P99 latency. - Важнее перцентили, а не average.

* USE Method (Infrastructure layer) - Resource-driven metrics, где USE = Utilization, Saturation, Errors- используется для хостов, контейнеров, VM.
USE method helps identify infrastructure bottlenecks.
U - Utilization: CPU %; Memory %; Disk usage %.
S - Saturation: Очереди; Backpressure; Resources at 100% - Network queue length; Thread pool queue.
E - Errors: Disk write errors; Network errors.

* Four Golden Signals (Google SRE) - If you can measure only four metrics for a user-facing system, measure these.
Golden Signals(RED + Saturation):
- Latency
- Traffic (Throughput)
- Errors
- Saturation

* Core Web Vitals (UI / Web ONLY) - важно для frontend и SEO - UX метрики
Core Web Vitals напрямую влияют на SEO - Google ранжирует сайты с учётом этих метрик.
- LCP - Largest Contentful Paint - Время, когда пользователь чувствует, что страница загрузилась.
- FID - First Input Delay - Когда пользователь может впервые взаимодействовать; perceived responsiveness.
- CLS - Cumulative Layout Shift - Насколько страница 'прыгает'; perceived stability.

Вопросы:
1. Какие методы мониторинга ты знаешь? RED method; USE method; Golden Signals; Core Web Vitals.
2. Чем RED отличается от USE? RED => service-level, user-facing; USE => infrastructure-level.
3. Что такое Golden Signals? Latency, traffic, errors, saturation - ключевые метрики Google SRE.
4. Почему average latency - плохая метрика? Потому что она скрывает хвосты, важнее P95/P99.
5. Зачем нужны Core Web Vitals?  UX; SEO ranking; perceived performance.

4) Observability. 
Monitoring - часть observability, но не наоборот. Они не конкурируют, а дополняют друг друга.

Monitoring vs Observability - отличие:
* Monitoring - Симптомы - Нужно заранее знать, ЧТО мониторить
Работает по принципу - Реактивный подход: 'Следим за CPU'; 'Следим за error rate'.
Хорошо отвечает на вопросы: WHEN (когда сломалось); WHERE (где сломалось).
Подходит для: monolith; систем с предсказуемыми точками отказа.
* Observability - Причины - Позволяет находить проблемы, о которых мы не подумали заранее и собирает actionable data со всей системы.
Даёт holistic view. 
Работает по принципу - Проактивный подход.
Хорошо отвечает на вопросы: WHY (почему это произошло).
Подходит для: microservices; distributed systems; сложных CI/CD систем.

Monitoring vs Observability по аналогии с машиной:
Monitoring - приборная панель - Видим, что что-то не так, но не знаем почему: RPM; скорость; warning lights.
Observability - диагностика у механика - Понимаем root cause, а не симптом: подключение к OBD; получение детальных данных; точное понимание причины.

Термины:
Tool sprawl - ситуация, когда: используется много разрозненных monitoring tools; нет единой картины системы; данные не коррелируют друг с другом.
Observability решает проблему Tool sprawl, объединяя: metrics; logs; traces.

Ключевая концепция: Unknown Unknowns - Observability помогает обнаружить unknown unknowns -
проблемы, о которых мы даже не знали, что они возможны.

Вопросы:
1. В чём разница между monitoring и observability? Monitoring tells us when and where something is wrong, observability helps us understand why it is wrong.
2. Почему monitoring недостаточно для microservices?  слишком много сервисов; сложные зависимости; непредсказуемые точки отказа; нужны коррелированные данные.
3. Что такое 'unknown unknowns'? Issues that we didn’t anticipate or define monitoring for in advance.
4. Что такое tool sprawl? Using many disconnected monitoring tools without a unified view of the system.

5) Методы сбора метрик (Push vs Scrape)
Существует 2 основных метода сбора метрик и сохранения их в time-series database: Push; Scrape.

* Push method - Метрики отправляются приложением в time-series DB или в агент.
- Приложение / микросервис сам отправляет метрики
- Используются протоколы: TCP / UDP / HTTP
- Часто используется agent / daemon для агрегации
Напр. Application => StatsD (agent) => Graphite (TSDB)

Зачем нужен агент (StatsD): 
- TSDB потребляет CPU и storage
- хранить каждую метрику дорого
- агент: принимает метрики; агрегирует (avg, sum, count); отправляет уже агрегированные данные.
!Push = application-driven metrics!

Плюсы:
+ удобно для: ephemeral сервисов; IoT; environments без inbound доступа.
+ приложение контролирует отправку

Минусы:
- сложнее контролировать нагрузку
- риск потерять метрики
- сложнее стандартизировать

* Scrape method - Метрики читаются извне системой мониторинга:  
- Приложение экспортирует метрики через endpoint; 
- Time-series DB сама приходит и читает метрики.
Напр. Application (/metrics) ← Prometheus
Принцип работы: приложение предоставляет HTTP endpoint => Prometheus знает адрес сервиса => Prometheus периодически scrape-ит метрики.
!Scrape = monitoring-driven metrics!

Плюсы:
+ централизованный контроль
+ легко масштабировать
+ стандарт для Kubernetes / cloud-native
+ Prometheus ecosystem

Минусы:
- нужен network access
- сложнее для: IoT; edge; NAT / firewalls.

!Push vs Scrape - это выбор, а не религия!
!Не надо слепо выбирать Prometheus только потому, что 'так делают все'!

Перед выбором нужно подумать:
- Тип систем: custom applications? OS / DB / infra?
- Scalability: новые сервисы? новые регионы? multi-geo?
- Complexity: IoT? edge devices? distributed world-wide?
- Network ограничения:inbound доступ есть? firewall / NAT?

Выбор зависит от: архитектуры; масштабов; окружения.

Вопросы:
1. Какие методы сбора метрик ты знаешь? Push и Scrape.
2. В чём разница между Push и Scrape? Push - приложение отправляет метрики. Scrape - система мониторинга читает метрики.
3. Пример Push-модели? Application => StatsD => Graphite.
4. Пример Scrape-модели? Prometheus => /metrics endpoint приложения.
5. Почему используют агрегацию в Push? Чтобы снизить нагрузку на TSDB и стоимость хранения.
6. Почему Prometheus популярен? Scrape model, cloud-native, Kubernetes-friendly.
7. Когда Push лучше Scrape? IoT; edge devices; нет inbound network доступа.
8. Главная ошибка при выборе Prometheus? Использовать его 'потому что модно', а не потому что подходит архитектуре.

6) Telemetry data (MELT), где M - Metrics; E - Events; L - Logs; T - Traces. 
В observability - 4 типа telemetry data.
* Events - это действие, которое произошло в конкретный момент времени.
- есть action
- есть timestamp
- показывает факт того, что что-то произошло
Напр. vending machine: покупка пачки чипсов в 3:20 PM
Где встречаются: event streaming platforms (Kafka); event-driven microservices.
!event подтверждает, что ожидаемое действие произошло!
!но не показывает частоту!
!Event ≠ metric!

* Metrics - это агрегированное значение событий за период времени.
- считает события
- агрегирует (count, rate, avg)
- всегда привязана ко времени
Напр. vending machine: 100 пачек чипсов в минуту
Зачем нужны: сравнение во времени; выявление трендов; деградация / рост.
Напр: сегодня: 100/мин => неделю назад: 200/мин => видим проблему, но не причину

* Logs - это детализированное описание события.
- содержит контекст
- содержит metadata
- гораздо подробнее, чем event
Напр. vending machine: продукт: chips; цена: $2; время: 3:20 PM; vending machine ID; локация: Sydney; payment method: Mastercard
!Logs = максимум деталей!

* Traces - это путь запроса через несколько сервисов.
- используется в microservices
- показывает взаимодействие сервисов
- помогает найти точку сбоя
Напр. vending machine => bank => Mastercard => bank => vending machine
!любой шаг может упасть - trace показывает где именно!
!Traces отвечают на вопрос: где запрос сломался!

* Связь между MELT
- Event - факт действия
- Metric - агрегированная статистика событий
- Log - подробности одного события
- Trace - путь запроса через систему

Вопросы:
1. Какие типы telemetry data ты знаешь? Metrics; Events; Logs; Traces (MELT).
2. Чем event отличается от metric? Event - одно действие в момент времени. Metric - агрегированное значение событий за период.
3. Зачем нужны metrics, если есть events? Metrics позволяют видеть тренды и сравнивать во времени.
4. Чем log отличается от event? Log содержит гораздо больше контекста и деталей.
5. Для чего нужны traces? Чтобы увидеть путь запроса через микросервисы и найти точку отказа.
6. Какие данные помогают найти root cause? Logs и traces (не metrics).

7) Prometheus: как собирать метрики (Exporters, Scrape, Push Gateway):
Prometheus (хранит и обрабатывает метрики) -- pull --> scrape (читает /metrics endpoint(HTTP GET)) --> Exporter (собирает и преобразует метрики) -- reads --> System (источник данных)

Базовая идея: Prometheus - это pull-based time series database.
!В Prometheus НЕЛЬЗЯ напрямую пушить метрики!

Проблема: не всегда есть доступ к source code системы, с которой нужно собрать метрики.
Примеры: базы данных (MySQL, PostgreSQL), OS (Linux, Windows), CloudWatch (AWS), HAProxy, IoT (датчики, сенсоры).
!Мы не можем: менять код MySQL, обновлять код миллионов IoT, позволить миллионам устройств пушить метрики в Prometheus (он задохнётся).

Антипаттерн: bash / PowerShell скрипты, cron jobs / scheduled tasks, ручной сбор и отправка метрик.
Минусы: не масштабируется, сложно поддерживать, нестабильно.

* Exporters - верное решение - это компонент, который: собирает метрики из системы и отдаёт их в формате, понятном Prometheus.
!Exporter = адаптер между системой и Prometheus!
Он может быть как установлен на системе (Linux exporter), так и установлен рядом (CloudWatch, HAProxy, IoT).
Примеры: Node Exporter (Linux), Windows Exporter, MySQL Exporter, CloudWatch Exporter, HAProxy Exporter.


* Scraping - это процесс, когда Prometheus подключается к exporter, читает метрики, сохраняет их у себя.
!Scrape = Prometheus pulls data!
- настраивается в prometheus.yml
- default scrape interval = 15 секунд
- Prometheus сам контролирует частоту и нагрузку

Scraping идеален, когда: 
- heterogeneous infrastructure
- много разных компонентов
- OS + DB + proxies + cloud services
- централизованный контроль 

* Push Gateway => часть Prometheus ecosystem, который содержит встроенный exporter - иногда приложение хочет отправить метрики само.
!Push Gateway НЕ делает Prometheus push-based!
Принцип работы:
- application => Push Gateway
- Push Gateway хранит метрики временно
- Prometheus scrapes Push Gateway
Используется для: batch jobs, short-lived jobs, cron jobs.
!Prometheus ВСЕГДА pull!

Вопросы:
1. Как Prometheus собирает метрики? Pull model (scraping).
2. Что такое exporter? Компонент, который собирает метрики из системы и отдаёт их Prometheus.
3. Зачем нужны exporters? Когда нет доступа к source code системы.
4. Что такое scraping? Процесс, когда Prometheus периодически читает метрики у exporter.
5. Почему нельзя напрямую пушить метрики в Prometheus? Prometheus архитектурно pull-based.
6. Зачем нужен Push Gateway? Для batch / short-lived jobs.
7. Делает ли Push Gateway Prometheus push-based? Нет. Prometheus всё равно scrapes.
8. Почему Push Gateway не рекомендуют для long-running services? Потеря семантики, stale metrics, проблемы с масштабированием.

8) Node Exporter - это официальный Prometheus exporter для сбора метрик Unix-based систем - exporter для Unix-based операционных систем.
!Node Exporter НЕ имеет отношения к Node.js!
Node = любая машина с Unix-based kernel: Linux, ubuntu, other Unix-like OS.
Является частью Prometheus project и поддерживается комьюнити, считается стандартом для инфраструктурных метрик
!есть official exporters, а есть third-party exporters, написанные другими компаниями и разработчиками.

Метрики(инфраструктурные метрики (USE method):
- CPU usage
- Memory usage
- Disk usage
- Network I/O
- Filesystem
- Load average
- Process / kernel metrics
!Это метрики уровня ОС, а не приложения!
!Node Exporter - foundation для infra monitoring!

!!! ДЛЯ .NET WINDOWS SERVER НУЖЕН Windows Exporter!
ПРЕДСТАВИМ, ЧТО РАБОТАЕТ НА ЛИНУКСЕ БУЭЭЭ СЕРВЕРЕ, ТОГДА:
[ .NET Application ]
  -- OpenTelemetry => Prometheus / Grafana
  |     (requests, errors, latency)
  |
[ Linux Server ]
  -- Node Exporter => Prometheus / Grafana
        (CPU, RAM, Disk, Network)
НО ЭТО ТАК СЛОЖИЛОСЬ ИСТОРИЧЕСКИ... СЕЙЧАС  ВМЕСТО ШИНДОУСОВ ВСЕ ЧАЩЕ ИЗ-ЗА КОРА ПРИЛОЖЕНИЯ РАЗВОРАЧИВАЮТ НА ЛИНУКС СЕРВАКАХ... ИЗ-ЗА КОНТЕЙНЕРОВ, КУБЕРНЕТИСОВ ВСЯКИХ. КЛАУДЫ ДЕШЕВЛЕ И ПРОЧАЯ ДЕВОПС МИШУРА, КОТОРАЯ РЯДОВОМУ ПРОГРАММИСТУ ДО ЛАМПОЧКИ. Т.Е ЕСЛИ У ТЕБЯ ЛЕГАСИ ГОВ... КОД... ТО ТАМ СКОРЕЙ ВСЕГО ВИНДА НА СЕРВАКЕ. 

.NET раньше => Windows Server + IIS
.NET сейчас => Linux + Docker + Kubernetes

Вопросы:
1. Что такое Node Exporter? Официальный Prometheus exporter для Unix-based систем.
2. Имеет ли Node Exporter отношение к Node.js? Нет.
3. Какие метрики собирает Node Exporter? CPU, memory, disk, network, filesystem, kernel metrics.
4. На каком уровне работает Node Exporter? Infrastructure / OS level.
5. Что значит 'official Prometheus exporter'? Часть Prometheus project и поддерживается его сообществом.
6. Можно ли расширять Node Exporter? Да, через pluggable collectors.

9) Prometheus data model (metrics, labels, time series) - в Prometheus все данные хранятся как time series -
значение метрики (timestamp (Unix timestamp))
!Prometheus = time series database!

Каждая time series в Prometheus уникально идентифицируется:
- metric name
- labels (key=value pairs) - способ разделять одну метрику на разные time series
	metric_name{key="value", key="value"}, где
	- labels в { } и могут быть 0, 1, n.
	Пример: для метрика auth_api_hit с labels: auth_api_hit{count="1", time_taken="800"}, где
	- auth_api_hit - metric name, count="1" - label, time_taken="800" - label
	!Одна метрика => много time series через labels!
Labels используются для: фильтрации, агрегации, группировки.
!Metric name + labels = unique time series!

!Prometheus не хранит 'объекты', он хранит числовые значения во времени.

Вопросы:
1. Как Prometheus хранит данные? Как time series (value + timestamp).
2. Что делает time series уникальной? Metric name + set of labels.
3. Что такое label в Prometheus? Key-value пара, описывающая измерение метрики.
4. Можно ли иметь метрику без labels? Да.
5. Зачем нужны labels? Для фильтрации, агрегации и разделения метрик.
6. Что важнее: metric name или labels? Оба: metric name определяет метрику, labels - её измерения.

10) Prometheus data types (Scalar, Instant Vector, Range Vector)
Prometheus имеет собственный query language - PromQL.

* Scalar - одно значение (float, string).
Пример метрики:
prometheus_http_requests_total{code="200", job="prometheus"}

prometheus_http_requests_total{job="prometheus", code=~"2.*"}
code=~"2.*" - код начинается с 2, например 200,201,204,205.
!Такую гибкость float не даёт!
! если написать code=200 - ничего не вернет - Label values в Prometheus ВСЕГДА строки.

! float используется:
- значение метрики
- результат вычислений
- результат PromQL выражений
пример:
http_requests_total 12345
cpu_usage 0.73
request_latency_ms 800

* Instant Vector - может быть:
- набор time series
- одна sample value
- один timestamp (now)
пример: auth_api_hit

* Instant Vector + filters
auth_api_hit{count="1", time_taken="800"}
1. искать метрик на основе metric name, т.е auth_api_hit
2. фильтровать time series по labels: count="1", time_taken="800"
и возвращает для каждого time series по одному значению на текущий момент времени
! НЕ ИСТОРИЮ 
! НЕ ДИАПАЗОН
т.е Instant Vector = фотография

* Range Vector
- набор time series
- много samples
- за указанный период времени
синтаксис:
metric_name[time_range]
пример:
auth_api_hit[5m]

Допустимые единицы времени
ms - milliseconds
s - seconds
m - minutes
h - hours
d - days (24h)
w - weeks (7d)
y - years (365d)
!Нет месяцев!
!Case-sensitive!

Вопросы:
1. Какие data types есть в Prometheus? Scalar, Instant Vector, Range Vector.
2. Что такое instant vector? Набор time series с одним sample на текущий момент.
3. Что такое range vector? Набор time series с samples за период времени.
4. Почему запрос с code=200 может не работать? Потому что значение было сохранено как string.
5. От чего зависит количество значений в range vector? От time range и scrape interval.
6. Можно ли использовать месяцы в range vector? Нет.

11) PromQL arithmetic operators (Scalar, Instant Vector)
+ - addition
- - subtraction
* - multiplication
/ - division
% - remainder
^ - power

* Scalar ⨯ Scalar = результат = scalar
2 + 2 = 4

* Scalar ⨯ Instant Vector = scalar применяется к каждому элементу instant vector
vector = [5, 6]
vector + 5 =>  [10, 11]
!Scalar применяется ко всем значениям vector!

* Instant Vector ⨯ Instant Vector = операция выполняется только для matching time series
time series - m1{label="c"}, metric name => m1 и labels => {label="c"}
matching = одинаковый metric name + одинаковые labels
если нет match - series пропадает
A: m1{label=a}, m1{label=b}, m1{label=c}
B: m1{label=a}, m1{label=b}

A + B => только label=a и label=b
!Нет matching labels => нет результата!

Вопросы:
1. Какие арифметические операторы есть в PromQL? +, -, *, /, %, ^
2. Что происходит при scalar + instant vector? Scalar применяется ко всем элементам vector.
3. Что происходит при instant vector + instant vector? Операция выполняется только для matching time series.
4. Когда time series не попадёт в результат? Если нет matching metric name и labels.
5. Изменяется ли исходный vector при операции? Нет, всегда создаётся новый vector.

12) PromQL binary comparison operators
такие же как и везде... ==, > и тд, и тп..

* Scalar ⨯ Instant Vector = оператор применяется к каждому элементу vector и остаются только те series, где условие true:
vector: [a=10, b=4]
vector == 10 => [a]
!Series, где условие false, исчезают!

* Instant Vector ⨯ Instant Vector = сравниваются только matching time series 
matching = metric name + labels
остаются series, где есть match и условие true.
A: m{a=10}, m{b=4}
B: m{a=10}, m{b=6}
A == B = m{a}

Вопросы:
1. Какие бинарные операторы есть в PromQL? ==, !=, >, <, >=, <=
2. Что возвращает comparison scalar vs scalar? 1 (true) или 0 (false).
3. Что происходит при scalar vs instant vector? Scalar применяется ко всем series, остаются только true.
4. Как работают comparison между двумя vectors? Только matching metric name + labels участвуют.
5. Почему часть series может пропасть? Нет match или условие false.

13) PromQL set binary operators (and / or / unless)
and
A: m{a=10}, m{b=4}
B: m{a=10}, m{c=4}

A and B => m{a}

or
A: m{a}, m{b}
B: m{a}, m{c}

A or B → m{a}, m{b}, m{c}

unless - только элементы из левого vector, которых НЕТ в правом.
A: m{a}, m{b}
B: m{a}, m{c}

A unless B → m{b}

Вопросы:
1. С какими типами данных работают set operators? Только instant vectors.
2. Чувствительны ли они к регистру? Да, всегда lowercase.

11) PromQL aggregation operators = агрегируют один Instant Vector = возвращают новый Instant Vector
!Агрегация всегда создаёт НОВЫЙ vector!
Основные:
sum - сумма значений
min - минимальное значение
max - максимальное значение
avg - среднее значение
count - количество элементов (time series)
count_values - считает элементы с одинаковым значением
group - группирует элементы, value всегда = 1
topk(k, vector) - k наибольших значений
bottomk(k, vector) - k наименьших значений
stddev - стандартное отклонение (population)
stdvar - дисперсия (population)

примеры:
sum(metric_name)
avg(metric_name)
topk(3, metric_name)
sum(metric) by (label)
sum(node_cpu_seconds_total) by (mode)

sum(metric) without (label)
sum(node_cpu_seconds_total) without (mode)
!without = убрать label перед агрегацией!

group(metric)
group(metric) by (label)
!value ВСЕГДА = 1!

topk / bottomk - возвращает только k элементов и часто используется вместе с avg, sum, rate
topk(3, metric)
bottomk(2, metric)
topk(5, avg(http_request_duration_seconds) by (service))

Вопросы:
1. Что делают aggregation operators? Агрегируют Instant Vector => возвращают новый Instant Vector.
2. Разница между by и without? by - группируем по label, without - исключаем label.
3. Для чего нужен group? Только группировка labels, значение всегда 1.
4. Когда использовать topk? Для поиска самых 'тяжёлых' сервисов / хостов / метрик.
5. Можно ли агрегировать Range Vector? Нет, сначала нужен Instant Vector (обычно через rate, avg_over_time).

12) Time offset в PromQL
offset - позволяет смотреть значения метрик в прошлом, а не latest scrape = если нужно значение N минут / часов / дней назад
пример:
metric_name offset 5m
metric_name offset 10m
metric_name offset 8h
metric_name offset 2d

!offset НЕ меняет тип данных

prometheus_http_requests_total            => value = 21 (now)
prometheus_http_requests_total offset 8m  => value = 20 (8 min ago)

правильная запись
avg(prometheus_http_requests_total offset 8h) by (code)

говно из жопы !!!!!
ГОВНО avg(prometheus_http_requests_total) by (code) offset 8h
ГОВНО avg(prometheus_http_requests_total by (code)) offset 8h

!!!offset применяется к метрике, а не к aggregation

* offset + aggregation
ПОРЯДОК: metric offset time → aggregation → by / without
пример:
avg(prometheus_http_requests_total offset 1h) by (code)

!group плохо для графиков
group(metric) by (label)
- value всегда = 1
- график всегда flat
- для графиков нужны sum / avg / count

типикал use-cases offset:
- сравнение now vs past
- baseline comparison
- что было час назад?
- анализ деградации
пример:
rate(http_requests_total[5m]) / rate(http_requests_total[5m] offset 1h)

Вопросы:
1. Где писать offset? Сразу после метрики, до aggregation.
2. Можно ли применять offset к aggregation? Нет

14) 
* PromQL functions (часть 1): absent, math, clamp
параша... нагугли и прочитай, энивей хуй запомнишь

примеры:
проверка, что метрика ПРОПАЛА
absent(node_cpu_seconds_total) → пусто
absent(node_cpu_seconds_total{cpu="random"}) → { } = 1

та ж опера, но с range vector
absent_over_time(node_cpu_seconds_total[1h])

обрезка значений
clamp_min(node_cpu_seconds_total, 300)
clamp_max(node_cpu_seconds_total, 150000)
clamp(node_cpu_seconds_total, 300, 150000)

* PromQL time & delta functions (day, weekday, delta)
day_of_month(metric)
day_of_week(metric)
delta(node_cpu_temperature[2h])
idelta()

* PromQL utility functions: log, sort, time, timestamp
sort(clamp(metric, 300, 150000))
sort_desc(metric)

timestamp(metric)            => now
timestamp(metric offset 1h)  => now - 1h

* Aggregation over time (*_over_time)
avg_over_time(metric[2h])

примерно так работает:
metric           => Instant Vector (now)
metric[2h]       => Range Vector (history)
avg_over_time()  => Instant Vector (1 value per series)

пример:
avg_over_time(node_cpu_seconds_total{cpu="0"}[2h])

15) Prometheus + Windows (WMI / Windows Exporter)
! У Prometheus НЕТ официального exporter’а для Windows
(в отличие от Node Exporter для Linux)
Но существуют third-party exporters, которые основаны на WMI.
WMI (Windows Management Instrumentation) — встроенная инфраструктура Windows для:
- получения системных метрик
- управления ОС
- автоматизации админских задач
!WMI != Prometheus
!Prometheus просто читает данные, которые exporter достаёт из WMI!
Сейчас эта залупа называется windows_exporter, раньше wmi_exporter(многие скуфы до сих пор так называют).

* Архитектура:
Windows OS
  ↓ (WMI)
Windows Exporter (port 9182)
  ↓ (HTTP /metrics)
Prometheus (scrape)

!Prometheus exporter слушает порт 9182 - написано в документации... так что хз, держи за факт.



